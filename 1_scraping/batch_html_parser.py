"""
ãƒ¦ãƒ¼ãƒãƒ¥ãƒ©ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ï¼ˆè¤‡æ•°HTMLä¸€æ‹¬å‡¦ç†ç‰ˆï¼‰

æ‰‹å‹•ã§ä¿å­˜ã—ãŸHTMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ä¸€æ‹¬ã§ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¾ã™ã€‚
Cloudflareãªã©ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚’å®Œå…¨ã«å›é¿ã§ãã¾ã™ã€‚

ä½¿ã„æ–¹:
1. ãƒ–ãƒ©ã‚¦ã‚¶ã§å„ãƒšãƒ¼ã‚¸ã‚’é–‹ã
2. å³ã‚¯ãƒªãƒƒã‚¯ â†’ ã€Œãƒšãƒ¼ã‚¸ã®ã‚½ãƒ¼ã‚¹ã‚’è¡¨ç¤ºã€
3. ã™ã¹ã¦é¸æŠã—ã¦ã‚³ãƒ”ãƒ¼ï¼ˆCtrl+A â†’ Ctrl+Cï¼‰
4. html_files/ ãƒ•ã‚©ãƒ«ãƒ€ã« page1.html, page2.html... ã¨ã—ã¦ä¿å­˜
5. python batch_html_parser.py ã‚’å®Ÿè¡Œ
"""

from bs4 import BeautifulSoup
import csv
import os
import glob

def extract_channels(html_content):
    """HTMLã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰ãƒãƒ£ãƒ³ãƒãƒ«æƒ…å ±ã‚’æŠ½å‡º"""
    soup = BeautifulSoup(html_content, 'html.parser')
    
    channel_list = soup.find('ul', class_='channel-list')
    
    if not channel_list:
        return []
    
    channels = []
    
    for li in channel_list.find_all('li'):
        try:
            # ãƒãƒ£ãƒ³ãƒãƒ«å
            title_elem = li.find('p', class_='title')
            channel_name = title_elem.text.strip() if title_elem else 'N/A'
            
            # ãƒãƒ£ãƒ³ãƒãƒ«URL
            more_link = li.find('a', href=True)
            channel_id = more_link['href'] if more_link else 'N/A'
            channel_url = f"https://yutura.net{channel_id}" if channel_id != 'N/A' else 'N/A'
            
            # ãƒãƒ£ãƒ³ãƒãƒ«ç™»éŒ²è€…æ•°
            people_icon = li.find('i', title='ãƒãƒ£ãƒ³ãƒãƒ«ç™»éŒ²è€…æ•°')
            subscribers = 'N/A'
            if people_icon:
                p_tag = people_icon.parent
                if p_tag:
                    icon_copy = people_icon.extract()
                    subscribers = p_tag.get_text(strip=True)
                    p_tag.insert(0, icon_copy)
            
            channels.append({
                'ãƒãƒ£ãƒ³ãƒãƒ«å': channel_name,
                'ãƒãƒ£ãƒ³ãƒãƒ«URL': channel_url,
                'ãƒãƒ£ãƒ³ãƒãƒ«ç™»éŒ²è€…æ•°': subscribers
            })
            
        except Exception as e:
            print(f"âš  ãƒãƒ£ãƒ³ãƒãƒ«æƒ…å ±ã®æŠ½å‡ºä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            continue
    
    return channels

def process_html_files(html_dir='../html_files'):
    """HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬å‡¦ç†"""
    print("=" * 60)
    print("ãƒ¦ãƒ¼ãƒãƒ¥ãƒ© è¤‡æ•°HTMLä¸€æ‹¬å‡¦ç†")
    print("=" * 60)
    print(f"HTMLãƒ•ã‚©ãƒ«ãƒ€: {html_dir}")
    print("=" * 60)
    print()
    
    # HTMLãƒ•ã‚©ãƒ«ãƒ€ã®å­˜åœ¨ç¢ºèª
    if not os.path.exists(html_dir):
        print(f"âœ— ãƒ•ã‚©ãƒ«ãƒ€ '{html_dir}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        print(f"  ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¦HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®ã—ã¦ãã ã•ã„ã€‚")
        return []
    
    # HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ï¼ˆpage1.html, page2.html ãªã©ã®é †ç•ªã§ï¼‰
    html_files = sorted(glob.glob(os.path.join(html_dir, 'page*.html')))
    
    if not html_files:
        # page*.html ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€ã™ã¹ã¦ã®.htmlãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¯¾è±¡
        html_files = sorted(glob.glob(os.path.join(html_dir, '*.html')))
    
    if not html_files:
        print(f"âœ— HTMLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        print(f"  {html_dir}/ ãƒ•ã‚©ãƒ«ãƒ€ã« page1.html, page2.html... ã‚’é…ç½®ã—ã¦ãã ã•ã„ã€‚")
        return []
    
    print(f"âœ“ {len(html_files)}å€‹ã®HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡ºã—ã¾ã—ãŸ")
    print()
    
    all_channels = []
    
    for i, html_file in enumerate(html_files, 1):
        filename = os.path.basename(html_file)
        print(f"[{i}/{len(html_files)}] {filename}")
        print("-" * 60)
        
        try:
            # HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            with open(html_file, 'r', encoding='utf-8') as f:
                html_content = f.read()
            
            # ãƒãƒ£ãƒ³ãƒãƒ«æƒ…å ±ã‚’æŠ½å‡º
            channels = extract_channels(html_content)
            
            if not channels:
                print(f"âš  ãƒãƒ£ãƒ³ãƒãƒ«æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            else:
                print(f"âœ“ {len(channels)}ä»¶ã®ãƒãƒ£ãƒ³ãƒãƒ«æƒ…å ±ã‚’æŠ½å‡º")
                all_channels.extend(channels)
                print(f"âœ“ ç´¯è¨ˆ: {len(all_channels)}ä»¶")
            
            print()
            
        except Exception as e:
            print(f"âœ— ã‚¨ãƒ©ãƒ¼: {e}")
            print()
            continue
    
    print("=" * 60)
    print(f"å‡¦ç†å®Œäº†: å…¨{len(html_files)}ãƒ•ã‚¡ã‚¤ãƒ«ã€åˆè¨ˆ{len(all_channels)}ä»¶")
    print("=" * 60)
    
    return all_channels

def save_to_csv(channels, filename='../data/output/yutura_batch_channels.csv'):
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    if not channels:
        print("\nä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
    os.makedirs(os.path.dirname(filename), exist_ok=True)
    
    with open(filename, 'w', encoding='utf-8-sig', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=['ãƒãƒ£ãƒ³ãƒãƒ«å', 'ãƒãƒ£ãƒ³ãƒãƒ«URL', 'ãƒãƒ£ãƒ³ãƒãƒ«ç™»éŒ²è€…æ•°'])
        writer.writeheader()
        writer.writerows(channels)
    
    print(f"\nâœ“ {len(channels)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ {filename} ã«ä¿å­˜ã—ã¾ã—ãŸ")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("\n" + "=" * 60)
    print("ãƒ¦ãƒ¼ãƒãƒ¥ãƒ© è¤‡æ•°HTMLä¸€æ‹¬å‡¦ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 60)
    print()
    
    # ========================================
    # è¨­å®š
    # ========================================
    html_dir = '../html_files'                                  # HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®ã™ã‚‹ãƒ•ã‚©ãƒ«ãƒ€
    output_filename = '../data/output/yutura_batch_channels.csv'  # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
    # ========================================
    
    # HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
    all_channels = process_html_files(html_dir)
    
    # çµæœã‚’è¡¨ç¤º
    if all_channels:
        print(f"\n{'=' * 60}")
        print("å–å¾—ã—ãŸãƒãƒ£ãƒ³ãƒãƒ«æƒ…å ±ï¼ˆæœ€åˆã®5ä»¶ï¼‰")
        print('=' * 60)
        for i, channel in enumerate(all_channels[:5], 1):
            print(f"\n{i}. {channel['ãƒãƒ£ãƒ³ãƒãƒ«å']}")
            print(f"   URL: {channel['ãƒãƒ£ãƒ³ãƒãƒ«URL']}")
            print(f"   ç™»éŒ²è€…æ•°: {channel['ãƒãƒ£ãƒ³ãƒãƒ«ç™»éŒ²è€…æ•°']}")
        
        if len(all_channels) > 5:
            print(f"\n... ä»– {len(all_channels) - 5}ä»¶")
        
        # CSVã«ä¿å­˜
        save_to_csv(all_channels, output_filename)
        
        print(f"\n{'=' * 60}")
        print("ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print('=' * 60)
    else:
        print("\nãƒãƒ£ãƒ³ãƒãƒ«æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        print(f"\nğŸ’¡ ãƒ’ãƒ³ãƒˆ:")
        print(f"- {html_dir}/ ãƒ•ã‚©ãƒ«ãƒ€ã« page1.html, page2.html... ã‚’é…ç½®ã—ã¦ãã ã•ã„")
        print(f"- è©³ç´°ã¯ {html_dir}/README.txt ã‚’å‚ç…§ã—ã¦ãã ã•ã„")

if __name__ == '__main__':
    main()